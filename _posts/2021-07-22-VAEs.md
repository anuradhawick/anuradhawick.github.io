---
title: Variational Auto Encoders in Bioinformatics
author: Anuradha Wickramarachchi
date: 2021-07-22 10:00:00 +1000
categories: []
tags: [Machine Learning]
math: true
mermaid: true
pin: false
---

## Introduction to variational autoencoders and their application Bioinformatics/Metagenomics analysis


Autoencoders, in general, intend to learn a lower-dimensional representation of data. One of the main advantages of autoencoders is that they are capable of learning much complex lower dimensions whereas PCA-like decompositions are limited by their linear nature. Feel free to have a look at my article about auto-encoders.

![](https://miro.medium.com/max/1400/1*uogTxM0a-lVa__VkjFBjew.jpeg)
_Photo by [Hitesh Choudhary](https://unsplash.com/@hiteshchoudhary?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/python?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)_

**As usual, I will be talking about an application in bioinformatics.**

In contrast to conventional auto-encoders (AEs), variational auto-encoders (VAEs) belong to the family of generative models. This is because the VAEs learn a latent distribution for the input data. So they are capable of reconstructing new data points given new points from those distributions. However, the generative aspect of VAEs is not quite often used since GANs are much better at that task.

...

Read the full article in [Medium](https://towardsdatascience.com/variational-autoencoders-and-bioinformatics-8a1828170031){:target="_blank"}.

### TLDR
* [GIST python notebook](https://gist.github.com/anuradhawick/0d5bd7f198757f57ab38aa08b790a91c){:target="_blank"}
* [Example from PyTorch](https://github.com/pytorch/examples/blob/master/vae/main.py){:target="_blank"}
